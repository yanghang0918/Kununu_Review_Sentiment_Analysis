{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5d22f-2567-491c-b007-c427507ced25",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-23T19:13:50.659361Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35318209-1bb7-4774-b3d0-e6c42633b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179469b8-73f2-4bcb-86ac-cd2a8f3e5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[reviews['position'].eq('employee')].reset_index(drop=True)\n",
    "reviews_sample = reviews.iloc[:20000, :]\n",
    "performance_reviews = reviews_sample[['uuid', 'type', 'company_uuid', 'company_name', 'image_text', 'positive_text', 'suggestion_text', \n",
    "                                      'negative_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f3110-e6d0-4e39-9263-18b3015431ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate words frequency\n",
    "def count_freq(text):\n",
    "\n",
    "    # Initialize a CountVectorizer\n",
    "    count_vectorizer = CountVectorizer(stop_words=stopwords.words('german'))\n",
    "    \n",
    "    # Fit and transform the reviews to get the word count matrix\n",
    "    count_matrix = count_vectorizer.fit_transform(text)\n",
    "    \n",
    "    # Get the feature names (words) from the vectorizer\n",
    "    feature_names = count_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Get the word count values for each word in each review\n",
    "    word_count_values = count_matrix.toarray()\n",
    "    \n",
    "    # Create a dictionary to store the word frequency for each review\n",
    "    word_frequencies_per_review = []\n",
    "    for row in word_count_values:\n",
    "        word_frequencies = {feature_names[i]: count for i, count in enumerate(row) if count > 0}\n",
    "        word_frequencies_per_review.append(word_frequencies)\n",
    "    \n",
    "    word_frequencies_per_review = dict(sorted(word_frequencies_per_review[0].items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return word_frequencies_per_review\n",
    "\n",
    "#\n",
    "freq_dict = {}\n",
    "for column in performance_reviews.columns:\n",
    "    if column.endswith('_text'):\n",
    "        text = ' '.join(performance_reviews[column].dropna())\n",
    "        text = [text]\n",
    "        freq = count_freq(text)\n",
    "        freq_dict[column] = freq\n",
    "# freq_dict['image_text']\n",
    "\n",
    "# get the keywords list for firm performence\n",
    "firm_performance = ['firma', 'unternehmen', 'filiale',  'fluktuation', 'leistungen', 'betriebliche', 'branche', 'tarif', 'überdurchschnittlich',\n",
    "                    'unterdurchschnittlich', 'durchschnittlich', 'umwelt', 'umweltbewusstsein', 'sozialbewusstsein', 'nachhaltigkeit', 'wert', \n",
    "                    'ausstattung', 'technik', 'equipment', 'technische', 'software', 'hardware', 'image', 'bewertungen', 'qualität','performance',\n",
    "                    'wachstum', 'umsatz','gewinn', 'wettbewerb', 'innovation','tendenz', 'fallend', 'steigend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dbfd11-600a-4bac-82b7-a4564aaa553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label all the cells related to keywords list\n",
    "def label_related_cells(df, keywords_list):\n",
    "    for column in df.columns:\n",
    "        if column.endswith('_text'):\n",
    "            # Create a new label column\n",
    "            df[column + '_labels'] = df[column].apply(\n",
    "                lambda x: any(\n",
    "                    any(word.lower().startswith(prefix.lower()) for prefix in keywords_list)\n",
    "                    for word in str(x).split()\n",
    "                )\n",
    "            )\n",
    "    return df\n",
    "\n",
    "performance_reviews = label_related_cells(performance_reviews, firm_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312fd5e-6bc6-454b-9685-7ea63a1f0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Model\n",
    "\n",
    "# Load the BERT model for German sentiment analysis\n",
    "MODEL_NAME = \"oliverguhr/german-sentiment-bert\"\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def get_sentiment_probabilities(text):\n",
    "    if not isinstance(text, str):  # Check for NaN or non-string values\n",
    "        return None, None\n",
    "\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probs = softmax(logits, dim=1)\n",
    "    negative_prob, _, positive_prob = probs[0]\n",
    "    total = negative_prob + positive_prob\n",
    "    return negative_prob.item()/total.item(), positive_prob.item()/total.item()\n",
    "\n",
    "def analyze_sentiment(df):\n",
    "    for column in df.columns:\n",
    "        if column.endswith('_text_labels'):\n",
    "            # Identify the corresponding text column\n",
    "            text_column = column.replace('_labels', '')\n",
    "            \n",
    "            for index, label in pd.DataFrame(df[column]).iterrows():\n",
    "                if label.all():  # If the label is True, perform sentiment analysis\n",
    "                    # Get the text content from the corresponding text column\n",
    "                    text_content = df.at[index, text_column]\n",
    "                    \n",
    "                    # Perform sentiment analysis using the BERT model\n",
    "                    if text_content and isinstance(text_content, str):\n",
    "                        negative_prob, positive_prob = get_sentiment_probabilities(text_content)\n",
    "                        \n",
    "                        # Assign sentiment label based on the higher probability\n",
    "                        sentiment = 'positive' if positive_prob > negative_prob else 'negative'\n",
    "                        \n",
    "                        df.at[index, text_column + '_sentiment'] = sentiment\n",
    "                        df.at[index, text_column + '_negative_prob'] = negative_prob\n",
    "                        df.at[index, text_column + '_positive_prob'] = positive_prob\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899bf13-39bc-4ed6-a6c9-fea76c2b3922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the function\n",
    "performance_reviews = analyze_sentiment(performance_reviews)\n",
    "performance_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767985c-9953-4e49-94eb-1f3c99295a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_final_sentiment(df):\n",
    "    # Initialize new columns for average probabilities and final sentiment\n",
    "    df['average_negative_prob'] = np.nan\n",
    "    df['average_positive_prob'] = np.nan\n",
    "    df['final_sentiment'] = np.nan\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract columns that end with '_negative_prob' and '_positive_prob'\n",
    "        negative_prob_columns = [col for col in df.columns if col.endswith('_negative_prob')]\n",
    "        positive_prob_columns = [col for col in df.columns if col.endswith('_positive_prob')]\n",
    "        \n",
    "        # Calculate the average negative and positive probabilities for each row\n",
    "        average_negative_prob = np.nanmean(row[negative_prob_columns])\n",
    "        average_positive_prob = np.nanmean(row[positive_prob_columns])\n",
    "        \n",
    "        # Assign the calculated averages to the new columns\n",
    "        df.at[index, 'average_negative_prob'] = average_negative_prob\n",
    "        df.at[index, 'average_positive_prob'] = average_positive_prob\n",
    "        \n",
    "        # Determine the final sentiment based on which average probability is larger\n",
    "        if np.isnan(average_negative_prob) and np.isnan(average_positive_prob):\n",
    "            # If both averages are NaN, assign NaN as the final sentiment\n",
    "            df.at[index, 'final_sentiment'] = np.nan\n",
    "        elif average_negative_prob > average_positive_prob:\n",
    "            df.at[index, 'final_sentiment'] = 'negative'\n",
    "        else:\n",
    "            df.at[index, 'final_sentiment'] = 'positive'\n",
    "    \n",
    "    return df\n",
    "\n",
    "performance_reviews = calculate_final_sentiment(performance_reviews)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "\n",
    "performance_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f30d6f-0b78-4d5f-b22e-7353b1883f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
